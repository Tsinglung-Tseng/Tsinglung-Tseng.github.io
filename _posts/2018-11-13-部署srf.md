# TensorFlow接口编程环境搭建

## 1. 从源码安装tensorflow：

### 1.1. 安装CUDA toolkit 9.1
如果已经安装过旧版本的cudatoolkit，需要先卸载，然后从官网下载deb（network）版本进行安装。

### 1.2. 安装cuDNN
按[这里](https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.1.1/prod/9.1_20180214/cudnn-9.1-linux-x64-v7.1)直接下载

* Navigate to your cudnnpath directory containing the cuDNN Tar file.
* Unzip the cuDNN package.

```bash
$ tar -xzvf cudnn-9.0-linux-x64-v7.tgz

# Copy the following files into theCUDA Toolkit directory.
$ sudo cp cuda/include/cudnn.h/usr/local/cuda/include
$ sudo cp cuda/lib64/libcudnn*/usr/local/cuda/lib64
$ sudo chmod a+r/usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
 ```

### 1.3. 安装bazel

```bash
sudo apt-get install openjdk-8-jdk 
echo "deb [arch=amd64]http://storage.googleapis.com/bazel-apt stable jdk1.8" | sudo tee/etc/apt/sources.list.d/bazel.list 
curlhttps://bazel.build/bazel-release.pub.gpg | sudo apt-key add -
sudo apt-get update && sudo apt-getinstall bazel 
sudo apt-get upgrade bazel 
```

### 1.4. 下载Tensorflow源码

```bash
git clone --recurse-submoduleshttps://github.com/tensorflow/tensorflow
```

### 1.5. 配置安装
参照tensorflow官网的install教程。

./configure

注意python的选择，cuda以及cudnn的版本号必须匹配。（我用的是tf1.6+python3.5.2+cuda9.1.85+cudnn7.1）

接着编译GPU版本的pip package：

```bash
bazel build --config=opt --config=cuda--cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0"//tensorflow/tools/pip_package:build_pip_package

# 创建.whl文件
bazel-bin/tensorflow/tools/pip_package/build_pip_package/tmp/tensorflow_pkg

# 安装tensorflow
sudo pip install/tmp/tensorflow_pkg/tensorflow-*[version]*.whl

# 检验安装是否完成，打开终端

$ python3
>>>import tensorflow as tf
>>>hello = tf.constant('Hello,TensorFlow!')
>>>sess = tf.Session()
>>>print(sess.run(hello)

# 如果安装完成，终端显示：
Hello,TensorFlow!
```

### 1.6. 注意GPU版本下需要指定要使用的GPU

方法1: 在执行的.py文件中加入下面的语句

```python
import os
os.environ["CUDA_VISIBLE_DEVICES"]= "0" #这里的0是节点上可用的GPU。
```

方法2: 执行.py脚本时使用

```python
CUDA_VISIBLE_DEVICES="1" pythonyour_python_file.py
```

## 2. 在TensorFlow中添加新的Op

### 2.1. Define the op's interface

指定op的名称，输入以及输出，以及想要的属性
注意：op命名按CamelCase格式，并且保证在所有注册的op中是独有的。

### 2.2. Implement the kernel for the op

定义好接口之后，需要提供一种或多种实现。
创造OpKernel的一个子类并重载Compute方法。这个方法利用一个OpKernelContext* 类型的变量来传递必要信息。

### 2.3. Register op with the TensorFlow system

指定约束条件，例如在何种设备上运行该op

```python
REGISTER_KERNEL_BUILDER(Name("ZeroOut").Device(DEVICE_CPU),ZeroOutOp);
```

### 2.4. GPU kernels

GPU kernel 的实现包含两部分，OpKernel, CUDA kernel 和启动代码。
 
### 2.5. 使用bazel编译（使用源码安装的情况）

在tensorflow/core/user_ops 路径下添加一个组建文件

```python
load("//tensorflow:tensorflow.bzl","tf_custom_op_library")
tf_custom_op_library(
name = "zero_out.so",
srcs =["zero_out.cc"],
)

# 然后在终端下执行
$bazel build --config opt //tensorflow/core/user_ops:zero_out.so
#生成的.so文件在bazel-bin/tensorflow/core/user_ops/路径下。
```

### 2.6. 在python中使用op

使用tf.load_op_library 函数来加载相应op

```python
#e.g.
Import tensorflow as tf
import os
os.environ["CUDA_VISIBLE_DEVICES"]= "0"
 
zero_out_module = tf.load_op_library('your zero_out.so path')
with tf.Session(''):
zero_out_module.zero_out([ [1,2], [3,4] ]).eval()
array([ [1, 0], [0, 0] ], dtype=int32)
```